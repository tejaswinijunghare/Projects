{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# load dataset\n",
    "df = pd.read_csv('D:/iPrimed/Persistence/Data/weight_height.csv', index_col=0)\n",
    "\n",
    "print(df)\n",
    "print(df.corr(method='pearson')) # check the correlation matrix\n",
    "\n",
    "x = df['Height'].values.reshape(-1,1) # we need a 2D arrary since there could be multiple independent variables. But in this case we only have one independent variable since this is a simple linear regression model. So we need to reshape the 1D array from DataFrame into a 2D array but the size of the second dimension is of course 1\n",
    "# -1 in reshape is used to tell numpy to determine the dimension of the input\n",
    "y = df['Weight'].values\n",
    "\n",
    "lr = LinearRegression(fit_intercept = True)\n",
    "lr.fit(x, y) # actual fitting of the model, note we are using 100% of the dataset for training\n",
    "y_pred = lr.predict(x)\n",
    "\n",
    "print('Coefficients = ', lr.coef_)\n",
    "print('Intercept = ', lr.intercept_)\n",
    "print('R^2 = ', lr.score(x, y)) # larger value, i.e., close to 1.0, is better\n",
    "print('Root MSE = ', math.sqrt(metrics.mean_squared_error(y_pred , y))) # smaller value, i.e., close to 0.0, is better\n",
    "\n",
    "x2 = sm.add_constant(x)\n",
    "ols = sm.OLS(y, x2)\n",
    "est = ols.fit()\n",
    "print(est.summary()) # this gives you a very nicely and comprehensive formatted report\n",
    "\n",
    "# plot the regression line\n",
    "plt.scatter(x, y,  color='black')\n",
    "plt.plot(x, y_pred, color='blue', linewidth=3)\n",
    "plt.title('Linear Regression Line')\n",
    "plt.xlabel('Height')\n",
    "plt.ylabel('Weight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('D:/iPrimed/Persistence/Data/weight_height.csv', index_col=0)\n",
    "\n",
    "x = df['Height'].values.reshape(-1,1)\n",
    "y = df['Weight'].values\n",
    "\n",
    "lr = LinearRegression(fit_intercept = True)\n",
    "lr.fit(x, y)\n",
    "y_pred = lr.predict(x)\n",
    "\n",
    "residuals = y - y_pred\n",
    "\n",
    "print(y)\n",
    "print(y_pred)\n",
    "print(residuals)\n",
    "\n",
    "plt.title('Residuals Analysis')\n",
    "plt.scatter(y_pred, residuals,  color='black')\n",
    "plt.xlabel('Predicted Value')\n",
    "plt.ylabel('Residual')\n",
    "plt.plot([52, 73], [0, 0], color='blue', linestyle='-', linewidth=1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('D:/iPrimed/Persistence/Data/weight_height.csv', index_col=0)\n",
    "\n",
    "x = df['Height'].values.reshape(-1,1)\n",
    "y = df['Weight'].values\n",
    "\n",
    "lr = LinearRegression(fit_intercept = True)\n",
    "lr.fit(x, y)\n",
    "y_pred = lr.predict(x)\n",
    "\n",
    "residuals = y - y_pred\n",
    "\n",
    "print(y)\n",
    "print(y_pred)\n",
    "print(residuals)\n",
    "\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('D:/iPrimed/Persistence/Data/weight_height.csv', index_col=0)\n",
    "\n",
    "plt.figure(0)\n",
    "df['Height'].hist()\n",
    "plt.figure(1)\n",
    "stats.probplot(df['Height'], dist=\"norm\", plot=plt)\n",
    "plt.figure(2)\n",
    "df['Weight'].hist()\n",
    "plt.figure(3)\n",
    "stats.probplot(df['Weight'], dist=\"norm\", plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "import scipy.stats as stats\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "df = pd.read_csv('D:/iPrimed/Persistence/Data/colleges.csv', index_col=0)\n",
    "df = df.drop('Type', axis=1)\n",
    "print(df)\n",
    "print(df.corr(method='pearson'))\n",
    "print()\n",
    "\n",
    "independent_variables = df.drop('GraduationPercent', axis=1)\n",
    "\n",
    "x = independent_variables.values\n",
    "y = df['GraduationPercent'].values\n",
    "\n",
    "lr = LinearRegression(fit_intercept = True)\n",
    "lr.fit(x, y)\n",
    "y_pred = lr.predict(x)\n",
    "\n",
    "print('Coefficients = ', lr.coef_)\n",
    "print('Intercept = ', lr.intercept_)\n",
    "print('R^2 = ', lr.score(x, y))\n",
    "print('Root MSE = ', math.sqrt(metrics.mean_squared_error(y_pred , y)))\n",
    "\n",
    "x2 = sm.add_constant(x)\n",
    "ols = sm.OLS(y, x2)\n",
    "est = ols.fit()\n",
    "print(est.summary())\n",
    "\n",
    "residuals = y - y_pred\n",
    "plt.figure(0)\n",
    "plt.title('Residuals Analysis')\n",
    "plt.scatter(y_pred, residuals,  color='black')\n",
    "plt.xlabel('Predicted Value')\n",
    "plt.ylabel('Residual')\n",
    "plt.plot([69, 95], [0, 0], color='blue', linestyle='-', linewidth=1)\n",
    "\n",
    "plt.figure(1)\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import feature_selection\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "df = pd.read_csv('D:/iPrimed/Persistence/Data/colleges.csv', index_col=0)\n",
    "df = df.drop('Type', axis=1)\n",
    "\n",
    "independent_variables = df.drop('GraduationPercent', axis=1)\n",
    "\n",
    "x = independent_variables.values\n",
    "y = df['GraduationPercent'].values\n",
    "\n",
    "# Returns F-scores of features and p-values of F-scores.\n",
    "print(feature_selection.f_regression(x, y, center=True))\n",
    "\n",
    "print()\n",
    "\n",
    "estimator = LinearRegression(fit_intercept = True)\n",
    "selector = feature_selection.RFE(estimator, 2, step=1)\n",
    "selector = selector.fit(x, y)\n",
    "#  Selected (i.e., estimated best) features are assigned rank 1.\n",
    "print(selector.ranking_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import feature_selection\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "df = pd.read_csv('D:/iPrimed/Persistence/Data/newsprint.csv')\n",
    "\n",
    "independent_variables = df.drop('Y', axis=1)\n",
    "\n",
    "x = independent_variables.values\n",
    "y = df['Y'].values\n",
    "\n",
    "print(feature_selection.f_regression(x, y, center=True))\n",
    "\n",
    "print()\n",
    "\n",
    "estimator = LinearRegression(fit_intercept = True)\n",
    "selector = feature_selection.RFE(estimator, 2, step=1)\n",
    "selector = selector.fit(x, y)\n",
    "print(selector.ranking_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "import statsmodels.api as sm\n",
    "\n",
    "df = pd.read_csv('D:/iPrimed/Persistence/Data/colleges.csv')\n",
    "df['University'] = 0\n",
    "\n",
    "for i in range(0, len(df.index)):\n",
    "\tif df.ix[i]['Type'] == 'University':\n",
    "\t\tdf.loc[i,'University'] = 1\n",
    "\n",
    "df = df.drop('School', axis=1)\n",
    "df = df.drop('Type', axis=1)\n",
    "\n",
    "print(df)\n",
    "\n",
    "independent_variables = df.drop('GraduationPercent', axis=1)\n",
    "\n",
    "x = independent_variables.values\n",
    "y = df['GraduationPercent'].values\n",
    "\n",
    "lr = LinearRegression(fit_intercept = True)\n",
    "lr.fit(x, y)\n",
    "y_pred = lr.predict(x)\n",
    "\n",
    "print('Coefficients = ', lr.coef_)\n",
    "print('Intercept = ', lr.intercept_)\n",
    "print('R^2 = ', lr.score(x, y))\n",
    "print('Root MSE = ', math.sqrt(metrics.mean_squared_error(y_pred , y)))\n",
    "\n",
    "x2 = sm.add_constant(x)\n",
    "ols = sm.OLS(y, x2)\n",
    "est = ols.fit()\n",
    "print(est.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bike Sharing Dataset\n",
    "\n",
    "This question is based on the Bike Sharing dataset taken from the UCI Machine Learning\n",
    "Repository (originally from http://capitalbikeshare.com/system-data) –\n",
    "http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset.\n",
    " \n",
    "The original source of the dataset is attributed to: \n",
    "Fanaee-T, H., Gama, J., “Event Labeling Combining Ensemble Detectors and\n",
    "Background Knowledge”, Progress in Artificial Intelligence, 2013, pp. 1-15, Springer\n",
    "Berlin Heidelberg. \n",
    "\n",
    "The dataset is concerned with the domain of bike sharing systems. Bike sharing systems are\n",
    "new generation of traditional bike rentals where whole process from membership, rental and\n",
    "return back has become automatic. Through these systems, user is able to easily rent a bike\n",
    "from a particular position and return back at another position. Currently, there are about over\n",
    "500 bike-sharing programs around the world which is composed of over 500 thousands\n",
    "bicycles. Today, there exists great interest in these systems due to their important role in\n",
    "traffic, environmental and health issues. \n",
    "\n",
    "Apart from interesting real world applications of bike sharing systems, the characteristics of\n",
    "data being generated by these systems make them attractive for research. Opposed to other\n",
    "transport services such as bus or subway, the duration of travel, departure and arrival position\n",
    "is explicitly recorded in these systems. This feature turns bike sharing system into a virtual\n",
    "sensor network that can be used for sensing mobility in the city. Hence, it is expected that\n",
    "most of important events in the city could be detected via monitoring these data.\n",
    "\n",
    "The dataset comes in two versions. In the first version, the rental bikes records are organized\n",
    "by day. In the second version, the rental bikes records are organized by hour of day. In\n",
    "general, you may think of one record in the first version for a particular day as being divided\n",
    "into 24 records in the second version, i.e., one for each hour of day. However, if a particular\n",
    "hour does not have a single bike being rented out; it will be excluded from the dataset. In\n",
    "other words, the first version of the dataset contains 731 observations but the second version\n",
    "of the dataset contains less than 731 x 24 = 17,544 observations. In fact, the second version of\n",
    "the dataset only has 17,379 observations. It is deemed that there is no missing data. This \n",
    "assignment is based on the second version of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "import scipy.stats as stats\n",
    "from sklearn import feature_selection\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "df = pd.read_csv('D:/iPrimed/Persistence/Data/bike-sharing-hour.csv')\n",
    "\n",
    "df = df.drop('instant',axis=1)\n",
    "df = df.drop('dteday',axis=1)\n",
    "#df = df.drop('season',axis=1)\n",
    "#df = df.drop('yr',axis=1)\n",
    "#df = df.drop('mnth',axis=1)\n",
    "season = pd.get_dummies(df['season'])\n",
    "\n",
    "weathersit = pd.get_dummies(df['weathersit'],prefix='weather')\n",
    "\n",
    "df = df.drop('season',axis=1)\n",
    "df = df.drop('weathersit',axis=1)\n",
    "\n",
    "df = pd.concat([df,season],axis=1)\n",
    "df = pd.concat([df,weathersit],axis=1)\n",
    "\n",
    "print(df)\n",
    "print(df.corr(method='pearson'))\n",
    "print()\n",
    "\n",
    "independent_variables = df.drop('cnt', axis=1)\n",
    "\n",
    "x = independent_variables.values\n",
    "x = normalize(x)\n",
    "y = df['cnt'].values\n",
    "print(feature_selection.f_regression(x, y, center=True))\n",
    "\n",
    "estimator = LinearRegression(fit_intercept = True)\n",
    "selector = feature_selection.RFE(estimator, 2, step=1)\n",
    "selector = selector.fit(x, y)\n",
    "#  Selected (i.e., estimated best) features are assigned rank 1.\n",
    "print(selector.ranking_)\n",
    "\n",
    "x2 = sm.add_constant(x)\n",
    "ols = sm.OLS(y, x2)\n",
    "est = ols.fit()\n",
    "print(est.summary())\n",
    "\n",
    "\n",
    "lr = LinearRegression(fit_intercept = True)\n",
    "lr.fit(x, y)\n",
    "y_pred = lr.predict(x)\n",
    "\n",
    "residuals = y - y_pred\n",
    "plt.figure(0)\n",
    "plt.title('Residuals Analysis')\n",
    "plt.scatter(y_pred, residuals,  color='black')\n",
    "plt.xlabel('Predicted Value')\n",
    "plt.ylabel('Residual')\n",
    "plt.plot([0, 50], [0, 0], color='blue', linestyle='-', linewidth=1)\n",
    "\n",
    "plt.figure(1)\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boston Housing Dataset\n",
    "\n",
    "Perform a multiple linear regression analysis on the Boston housing dataset and report your\n",
    "results and findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "import scipy.stats as stats\n",
    "from sklearn import feature_selection\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "df = pd.read_csv('D:/iPrimed/Persistence/Data/BostonHousing.csv')\n",
    "\n",
    "print(df)\n",
    "print(df.corr(method='pearson'))\n",
    "print()\n",
    "\n",
    "independent_variables = df.drop('MEDV', axis=1)\n",
    "\n",
    "\n",
    "df = df.drop('CRIM',axis=1)\n",
    "df = df.drop('ZN',axis=1)\n",
    "df = df.drop('INDUS',axis=1)\n",
    "df = df.drop('AGE',axis=1)\n",
    "df = df.drop('RAD',axis=1)\n",
    "df = df.drop('TAX',axis=1)\n",
    "df = df.drop('LSTAT',axis=1)\n",
    "df = df.drop('B',axis=1)\n",
    "\n",
    "\n",
    "x = independent_variables.values\n",
    "y = df['MEDV'].values\n",
    "print(feature_selection.f_regression(x, y, center=True))\n",
    "\n",
    "estimator = LinearRegression(fit_intercept = True)\n",
    "selector = feature_selection.RFE(estimator, 2, step=1)\n",
    "selector = selector.fit(x, y)\n",
    "#  Selected (i.e., estimated best) features are assigned rank 1.\n",
    "print(selector.ranking_)\n",
    "\n",
    "a = selector.ranking_\n",
    "\n",
    "x2 = sm.add_constant(x)\n",
    "ols = sm.OLS(y, x2)\n",
    "est = ols.fit()\n",
    "print(est.summary())\n",
    "\n",
    "lr = LinearRegression(fit_intercept = True)\n",
    "lr.fit(x, y)\n",
    "y_pred = lr.predict(x)\n",
    "\n",
    "residuals = y - y_pred\n",
    "plt.figure(0)\n",
    "plt.title('Residuals Analysis')\n",
    "plt.scatter(y_pred, residuals,  color='black')\n",
    "plt.xlabel('Predicted Value')\n",
    "plt.ylabel('Residual')\n",
    "plt.plot([0, 50], [0, 0], color='blue', linestyle='-', linewidth=1)\n",
    "\n",
    "plt.figure(1)\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "Higher the F score , better, that is more likely it is the independant variable\n",
    "'''\n",
    "'''\n",
    "print(independent_variables.columns.values)\n",
    "independent_variables2 = []\n",
    "\n",
    "for i in range(len(independent_variables.columns.values)):\n",
    "    if a[i] < 4:\n",
    "        independent_variables2[independent_variables.columns.values[i]] = independent_variables[independent_variables.columns.values[i]]\n",
    "print('Independant varaibles 2')\n",
    "print(independent_variables2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing packages\n",
    "\n",
    "import numpy as np   #Importing Numpy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn as sklearn\n",
    "\n",
    "# Importing the dataset\n",
    "logistic_dataset = pd.read_csv('D:/iPrimed/Persistence/Data/Social_Network_Ads.csv')\n",
    "\n",
    "logistic_X = logistic_dataset.iloc[:, [2, 3]].values #Causes\n",
    "\n",
    "logistic_y = logistic_dataset.iloc[:, 4].values #Effect\n",
    "\n",
    "#Descriptive statistics\n",
    "type(logistic_dataset)\n",
    "type(logistic_dataset.Gender)\n",
    "type(logistic_dataset.Age)\n",
    "type(logistic_dataset.EstimatedSalary)\n",
    "type(logistic_dataset.Purchased)\n",
    "\n",
    "logistic_dataset.dtypes\n",
    "logistic_dataset.Age.mean()\n",
    "logistic_dataset.describe()\n",
    "\n",
    "#Exploratory Analysis\n",
    "sns.pairplot(logistic_dataset)\n",
    "plt.scatter(logistic_dataset.Age,logistic_dataset.EstimatedSalary)\n",
    "plt.scatter(logistic_dataset.EstimatedSalary,logistic_dataset.Purchased)\n",
    "\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "logistic_X_train, logistic_X_test, logistic_y_train, logistic_y_test = train_test_split(logistic_X, logistic_y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(logistic_X_train)\n",
    "X_test = sc.transform(logistic_X_test)\n",
    "\n",
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_classifier = LogisticRegression(random_state = 0)\n",
    "\n",
    "logistic_classifier.fit(logistic_X_train, logistic_y_train)\n",
    "\n",
    "logistic_classifier\n",
    "\n",
    "\n",
    "logistic_classifier.coef_\n",
    "\n",
    "# Predicting the Test set results\n",
    "logistic_y_pred = logistic_classifier.predict(logistic_X_test)\n",
    "\n",
    "Y_Test=pd.DataFrame(logistic_y_test)\n",
    "Y_Pred=pd.DataFrame(logistic_y_pred)\n",
    "comparison=[Y_Test,Y_Pred]\n",
    "pd.concat(comparison,axis=1)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "logistic_cm = confusion_matrix(logistic_y_test, \n",
    "                               logistic_y_pred)\n",
    "\n",
    "cross_tab=pd.crosstab(logistic_y_pred,logistic_y_test)\n",
    "print(\"Cross Tabulation\")\n",
    "print(cross_tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Reading data\n",
    "data = pd.read_csv(r\"D:/iPrimed/Persistence/Data/Social_Network_Ads.csv\")\n",
    "\n",
    "#Removing User ID, as it's an incremental value that doesn't add to our classification prediction\n",
    "data.pop('User ID')\n",
    "\n",
    "#Replacing categorical values to numericals\n",
    "data['Gender'].replace(['Male','Female'],[1,0],inplace=True)\n",
    "\n",
    "#Using features: Gender, Age for prediction of Purchased label\n",
    "feature_cols = ['Gender', 'Age']\n",
    "X = data[feature_cols] # Features\n",
    "y = data.Purchased # Target variable\n",
    "\n",
    "#Divide the data into train and test split. \n",
    "#The following code will split the data-set into 70% training data and 30% of testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)\n",
    "\n",
    "#Train the model with the help of DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#At last we need to make predictions. It can be done with the help of following script −\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#Next, we can get the accuracy score, confusion matrix and classification report as follows −\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "result = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cross_tab=pd.crosstab(y_pred,y_test)\n",
    "print(\"Cross Tabulation\")\n",
    "print(cross_tab)\n",
    "\n",
    "result1 = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\",)\n",
    "print (result1)\n",
    "\n",
    "result2 = accuracy_score(y_test,y_pred)\n",
    "print(\"Accuracy:\",result2)\n",
    "\n",
    "#Visualizing Decision Tree\n",
    "#The above decision tree can be visualized with the help of following code −\n",
    "#from sklearn.tree import export_graphviz\n",
    "#from sklearn.externals.six import StringIO\n",
    "#from IPython.display import Image\n",
    "#import pydotplus\n",
    "#dot_data = StringIO()\n",
    "#export_graphviz(clf, out_file=dot_data, filled=True, rounded=True,\n",
    "#   special_characters=True,feature_names = feature_cols,class_names=['0','1'])\n",
    "#graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "#graph.write_png('Purchased.png')\n",
    "#Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised Learning - Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Market Segmentation\n",
    " \n",
    "#Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sklearn\n",
    "sns.set()\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    " \n",
    "data = pd.read_csv('D:/iPrimed/Persistence/Data/satisfaction.csv')\n",
    "\n",
    "\n",
    " \n",
    "data.head()\n",
    "data.tail()\n",
    "data.dtypes\n",
    "type(data)\n",
    "data.columns\n",
    "data.axes\n",
    "data.size\n",
    "data.ndim\n",
    "data.shape\n",
    "data.describe()\n",
    "data.mean()\n",
    "data.std()\n",
    "data.groupby('Gender').mean()\n",
    "data_men = data[data['Gender']=='Men']\n",
    "data_women = data[data['Gender']=='Women']\n",
    "data_men.head()\n",
    "data_women.head()\n",
    "data_men.describe()\n",
    "data_women.describe()\n",
    "data.corr()\n",
    "data_men.corr()\n",
    "data_women.corr()\n",
    " \n",
    "\n",
    "plt.scatter(data['Satisfaction'],data['Loyalty'])\n",
    "plt.xlabel('Satisfaction')\n",
    "plt.ylabel('Loyalty')\n",
    "\n",
    "plt.scatter(data_men['Satisfaction'],data_men['Loyalty'])\n",
    "plt.xlabel('Satisfaction of Men')\n",
    "plt.ylabel('Loyalty of Men')\n",
    "\n",
    "plt.scatter(data_women['Satisfaction'],data_women['Loyalty'])\n",
    "plt.xlabel('Satisfaction of Women')\n",
    "plt.ylabel('Loyalty of Women')\n",
    "\n",
    "x = data.copy()\n",
    "x = data.iloc[:,:2]\n",
    "kmeans = KMeans(5)\n",
    "kmeans.fit(x)\n",
    "clusters = x.copy()\n",
    "clusters['predict']=kmeans.fit_predict(x)\n",
    "\n",
    "plt.scatter(clusters['Satisfaction'], clusters['Loyalty'], c=clusters['predict'], cmap='rainbow')\n",
    "\n",
    "plt.xlabel('Satisfaction')\n",
    "plt.ylabel('Loyalty')\n",
    "\n",
    "report = pd.concat([data,clusters['predict']],axis=1)\n",
    "\n",
    "report.to_csv('report.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
